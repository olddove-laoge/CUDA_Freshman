//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-35404655
// Cuda compilation tools, release 12.8, V12.8.61
// Based on NVVM 7.0.1
//

.version 8.7
.target sm_52
.address_size 64

	// .globl	_Z6warmupPiS_j

.visible .entry _Z6warmupPiS_j(
	.param .u64 _Z6warmupPiS_j_param_0,
	.param .u64 _Z6warmupPiS_j_param_1,
	.param .u32 _Z6warmupPiS_j_param_2
)
{
	.reg .pred 	%p<6>;
	.reg .b32 	%r<16>;
	.reg .b64 	%rd<13>;


	ld.param.u64 	%rd3, [_Z6warmupPiS_j_param_0];
	ld.param.u64 	%rd4, [_Z6warmupPiS_j_param_1];
	ld.param.u32 	%r6, [_Z6warmupPiS_j_param_2];
	mov.u32 	%r1, %tid.x;
	setp.ge.u32 	%p1, %r1, %r6;
	@%p1 bra 	$L__BB0_8;

	mov.u32 	%r2, %ctaid.x;
	mov.u32 	%r3, %ntid.x;
	mul.lo.s32 	%r7, %r2, %r3;
	cvta.to.global.u64 	%rd5, %rd3;
	mul.wide.u32 	%rd6, %r7, 4;
	add.s64 	%rd1, %rd5, %rd6;
	setp.lt.u32 	%p2, %r3, 2;
	@%p2 bra 	$L__BB0_6;

	mul.wide.u32 	%rd7, %r1, 4;
	add.s64 	%rd2, %rd1, %rd7;
	mov.u32 	%r15, 1;

$L__BB0_3:
	shl.b32 	%r5, %r15, 1;
	rem.u32 	%r9, %r1, %r5;
	setp.ne.s32 	%p3, %r9, 0;
	@%p3 bra 	$L__BB0_5;

	add.s32 	%r10, %r15, %r1;
	mul.wide.u32 	%rd8, %r10, 4;
	add.s64 	%rd9, %rd1, %rd8;
	ld.global.u32 	%r11, [%rd2];
	ld.global.u32 	%r12, [%rd9];
	add.s32 	%r13, %r11, %r12;
	st.global.u32 	[%rd2], %r13;

$L__BB0_5:
	bar.sync 	0;
	setp.lt.u32 	%p4, %r5, %r3;
	mov.u32 	%r15, %r5;
	@%p4 bra 	$L__BB0_3;

$L__BB0_6:
	setp.ne.s32 	%p5, %r1, 0;
	@%p5 bra 	$L__BB0_8;

	ld.global.u32 	%r14, [%rd1];
	cvta.to.global.u64 	%rd10, %rd4;
	mul.wide.u32 	%rd11, %r2, 4;
	add.s64 	%rd12, %rd10, %rd11;
	st.global.u32 	[%rd12], %r14;

$L__BB0_8:
	ret;

}
	// .globl	_Z13reduceUnroll2PiS_j
.visible .entry _Z13reduceUnroll2PiS_j(
	.param .u64 _Z13reduceUnroll2PiS_j_param_0,
	.param .u64 _Z13reduceUnroll2PiS_j_param_1,
	.param .u32 _Z13reduceUnroll2PiS_j_param_2
)
{
	.reg .pred 	%p<7>;
	.reg .b32 	%r<21>;
	.reg .b64 	%rd<17>;


	ld.param.u64 	%rd5, [_Z13reduceUnroll2PiS_j_param_0];
	ld.param.u64 	%rd4, [_Z13reduceUnroll2PiS_j_param_1];
	ld.param.u32 	%r10, [_Z13reduceUnroll2PiS_j_param_2];
	cvta.to.global.u64 	%rd1, %rd5;
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %ntid.x;
	mul.lo.s32 	%r11, %r1, %r2;
	shl.b32 	%r3, %r11, 1;
	mov.u32 	%r4, %tid.x;
	add.s32 	%r5, %r3, %r4;
	setp.ge.u32 	%p1, %r4, %r10;
	@%p1 bra 	$L__BB1_10;

	add.s32 	%r6, %r5, %r2;
	setp.ge.u32 	%p2, %r6, %r10;
	@%p2 bra 	$L__BB1_3;

	mul.wide.u32 	%rd6, %r6, 4;
	add.s64 	%rd7, %rd1, %rd6;
	mul.wide.u32 	%rd8, %r5, 4;
	add.s64 	%rd9, %rd1, %rd8;
	ld.global.u32 	%r12, [%rd9];
	ld.global.u32 	%r13, [%rd7];
	add.s32 	%r14, %r12, %r13;
	st.global.u32 	[%rd9], %r14;

$L__BB1_3:
	mul.wide.u32 	%rd10, %r3, 4;
	add.s64 	%rd2, %rd1, %rd10;
	bar.sync 	0;
	shr.u32 	%r20, %r2, 1;
	setp.eq.s32 	%p3, %r20, 0;
	@%p3 bra 	$L__BB1_8;

	mul.wide.u32 	%rd11, %r4, 4;
	add.s64 	%rd3, %rd2, %rd11;

$L__BB1_5:
	setp.ge.u32 	%p4, %r4, %r20;
	@%p4 bra 	$L__BB1_7;

	add.s32 	%r15, %r20, %r4;
	mul.wide.u32 	%rd12, %r15, 4;
	add.s64 	%rd13, %rd2, %rd12;
	ld.global.u32 	%r16, [%rd3];
	ld.global.u32 	%r17, [%rd13];
	add.s32 	%r18, %r16, %r17;
	st.global.u32 	[%rd3], %r18;

$L__BB1_7:
	bar.sync 	0;
	shr.u32 	%r20, %r20, 1;
	setp.ne.s32 	%p5, %r20, 0;
	@%p5 bra 	$L__BB1_5;

$L__BB1_8:
	setp.ne.s32 	%p6, %r4, 0;
	@%p6 bra 	$L__BB1_10;

	ld.global.u32 	%r19, [%rd2];
	cvta.to.global.u64 	%rd14, %rd4;
	mul.wide.u32 	%rd15, %r1, 4;
	add.s64 	%rd16, %rd14, %rd15;
	st.global.u32 	[%rd16], %r19;

$L__BB1_10:
	ret;

}
	// .globl	_Z13reduceUnroll4PiS_j
.visible .entry _Z13reduceUnroll4PiS_j(
	.param .u64 _Z13reduceUnroll4PiS_j_param_0,
	.param .u64 _Z13reduceUnroll4PiS_j_param_1,
	.param .u32 _Z13reduceUnroll4PiS_j_param_2
)
{
	.reg .pred 	%p<7>;
	.reg .b32 	%r<27>;
	.reg .b64 	%rd<21>;


	ld.param.u64 	%rd5, [_Z13reduceUnroll4PiS_j_param_0];
	ld.param.u64 	%rd4, [_Z13reduceUnroll4PiS_j_param_1];
	ld.param.u32 	%r10, [_Z13reduceUnroll4PiS_j_param_2];
	cvta.to.global.u64 	%rd1, %rd5;
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %ntid.x;
	mul.lo.s32 	%r11, %r1, %r2;
	shl.b32 	%r3, %r11, 2;
	mov.u32 	%r4, %tid.x;
	add.s32 	%r5, %r3, %r4;
	setp.ge.u32 	%p1, %r4, %r10;
	@%p1 bra 	$L__BB2_10;

	add.s32 	%r6, %r5, %r2;
	setp.ge.u32 	%p2, %r6, %r10;
	@%p2 bra 	$L__BB2_3;

	mul.wide.u32 	%rd6, %r6, 4;
	add.s64 	%rd7, %rd1, %rd6;
	mul.wide.u32 	%rd8, %r5, 4;
	add.s64 	%rd9, %rd1, %rd8;
	ld.global.u32 	%r12, [%rd9];
	ld.global.u32 	%r13, [%rd7];
	add.s32 	%r14, %r12, %r13;
	st.global.u32 	[%rd9], %r14;
	add.s32 	%r15, %r6, %r2;
	mul.wide.u32 	%rd10, %r15, 4;
	add.s64 	%rd11, %rd1, %rd10;
	ld.global.u32 	%r16, [%rd11];
	add.s32 	%r17, %r16, %r14;
	st.global.u32 	[%rd9], %r17;
	add.s32 	%r18, %r15, %r2;
	mul.wide.u32 	%rd12, %r18, 4;
	add.s64 	%rd13, %rd1, %rd12;
	ld.global.u32 	%r19, [%rd13];
	add.s32 	%r20, %r19, %r17;
	st.global.u32 	[%rd9], %r20;

$L__BB2_3:
	mul.wide.u32 	%rd14, %r3, 4;
	add.s64 	%rd2, %rd1, %rd14;
	bar.sync 	0;
	shr.u32 	%r26, %r2, 1;
	setp.eq.s32 	%p3, %r26, 0;
	@%p3 bra 	$L__BB2_8;

	mul.wide.u32 	%rd15, %r4, 4;
	add.s64 	%rd3, %rd2, %rd15;

$L__BB2_5:
	setp.ge.u32 	%p4, %r4, %r26;
	@%p4 bra 	$L__BB2_7;

	add.s32 	%r21, %r26, %r4;
	mul.wide.u32 	%rd16, %r21, 4;
	add.s64 	%rd17, %rd2, %rd16;
	ld.global.u32 	%r22, [%rd3];
	ld.global.u32 	%r23, [%rd17];
	add.s32 	%r24, %r22, %r23;
	st.global.u32 	[%rd3], %r24;

$L__BB2_7:
	bar.sync 	0;
	shr.u32 	%r26, %r26, 1;
	setp.ne.s32 	%p5, %r26, 0;
	@%p5 bra 	$L__BB2_5;

$L__BB2_8:
	setp.ne.s32 	%p6, %r4, 0;
	@%p6 bra 	$L__BB2_10;

	ld.global.u32 	%r25, [%rd2];
	cvta.to.global.u64 	%rd18, %rd4;
	mul.wide.u32 	%rd19, %r1, 4;
	add.s64 	%rd20, %rd18, %rd19;
	st.global.u32 	[%rd20], %r25;

$L__BB2_10:
	ret;

}
	// .globl	_Z13reduceUnroll8PiS_j
.visible .entry _Z13reduceUnroll8PiS_j(
	.param .u64 _Z13reduceUnroll8PiS_j_param_0,
	.param .u64 _Z13reduceUnroll8PiS_j_param_1,
	.param .u32 _Z13reduceUnroll8PiS_j_param_2
)
{
	.reg .pred 	%p<7>;
	.reg .b32 	%r<39>;
	.reg .b64 	%rd<29>;


	ld.param.u64 	%rd5, [_Z13reduceUnroll8PiS_j_param_0];
	ld.param.u64 	%rd4, [_Z13reduceUnroll8PiS_j_param_1];
	ld.param.u32 	%r10, [_Z13reduceUnroll8PiS_j_param_2];
	cvta.to.global.u64 	%rd1, %rd5;
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %ntid.x;
	mul.lo.s32 	%r11, %r1, %r2;
	shl.b32 	%r3, %r11, 3;
	mov.u32 	%r4, %tid.x;
	add.s32 	%r5, %r3, %r4;
	setp.ge.u32 	%p1, %r4, %r10;
	@%p1 bra 	$L__BB3_10;

	add.s32 	%r6, %r5, %r2;
	setp.ge.u32 	%p2, %r6, %r10;
	@%p2 bra 	$L__BB3_3;

	mul.wide.u32 	%rd6, %r6, 4;
	add.s64 	%rd7, %rd1, %rd6;
	mul.wide.u32 	%rd8, %r5, 4;
	add.s64 	%rd9, %rd1, %rd8;
	ld.global.u32 	%r12, [%rd9];
	ld.global.u32 	%r13, [%rd7];
	add.s32 	%r14, %r12, %r13;
	st.global.u32 	[%rd9], %r14;
	add.s32 	%r15, %r6, %r2;
	mul.wide.u32 	%rd10, %r15, 4;
	add.s64 	%rd11, %rd1, %rd10;
	ld.global.u32 	%r16, [%rd11];
	add.s32 	%r17, %r16, %r14;
	st.global.u32 	[%rd9], %r17;
	add.s32 	%r18, %r15, %r2;
	mul.wide.u32 	%rd12, %r18, 4;
	add.s64 	%rd13, %rd1, %rd12;
	ld.global.u32 	%r19, [%rd13];
	add.s32 	%r20, %r19, %r17;
	st.global.u32 	[%rd9], %r20;
	add.s32 	%r21, %r18, %r2;
	mul.wide.u32 	%rd14, %r21, 4;
	add.s64 	%rd15, %rd1, %rd14;
	ld.global.u32 	%r22, [%rd15];
	add.s32 	%r23, %r22, %r20;
	st.global.u32 	[%rd9], %r23;
	add.s32 	%r24, %r21, %r2;
	mul.wide.u32 	%rd16, %r24, 4;
	add.s64 	%rd17, %rd1, %rd16;
	ld.global.u32 	%r25, [%rd17];
	add.s32 	%r26, %r25, %r23;
	st.global.u32 	[%rd9], %r26;
	add.s32 	%r27, %r24, %r2;
	mul.wide.u32 	%rd18, %r27, 4;
	add.s64 	%rd19, %rd1, %rd18;
	ld.global.u32 	%r28, [%rd19];
	add.s32 	%r29, %r28, %r26;
	st.global.u32 	[%rd9], %r29;
	add.s32 	%r30, %r27, %r2;
	mul.wide.u32 	%rd20, %r30, 4;
	add.s64 	%rd21, %rd1, %rd20;
	ld.global.u32 	%r31, [%rd21];
	add.s32 	%r32, %r31, %r29;
	st.global.u32 	[%rd9], %r32;

$L__BB3_3:
	mul.wide.u32 	%rd22, %r3, 4;
	add.s64 	%rd2, %rd1, %rd22;
	bar.sync 	0;
	shr.u32 	%r38, %r2, 1;
	setp.eq.s32 	%p3, %r38, 0;
	@%p3 bra 	$L__BB3_8;

	mul.wide.u32 	%rd23, %r4, 4;
	add.s64 	%rd3, %rd2, %rd23;

$L__BB3_5:
	setp.ge.u32 	%p4, %r4, %r38;
	@%p4 bra 	$L__BB3_7;

	add.s32 	%r33, %r38, %r4;
	mul.wide.u32 	%rd24, %r33, 4;
	add.s64 	%rd25, %rd2, %rd24;
	ld.global.u32 	%r34, [%rd3];
	ld.global.u32 	%r35, [%rd25];
	add.s32 	%r36, %r34, %r35;
	st.global.u32 	[%rd3], %r36;

$L__BB3_7:
	bar.sync 	0;
	shr.u32 	%r38, %r38, 1;
	setp.ne.s32 	%p5, %r38, 0;
	@%p5 bra 	$L__BB3_5;

$L__BB3_8:
	setp.ne.s32 	%p6, %r4, 0;
	@%p6 bra 	$L__BB3_10;

	ld.global.u32 	%r37, [%rd2];
	cvta.to.global.u64 	%rd26, %rd4;
	mul.wide.u32 	%rd27, %r1, 4;
	add.s64 	%rd28, %rd26, %rd27;
	st.global.u32 	[%rd28], %r37;

$L__BB3_10:
	ret;

}
	// .globl	_Z17reduceUnrollWarp8PiS_j
.visible .entry _Z17reduceUnrollWarp8PiS_j(
	.param .u64 _Z17reduceUnrollWarp8PiS_j_param_0,
	.param .u64 _Z17reduceUnrollWarp8PiS_j_param_1,
	.param .u32 _Z17reduceUnrollWarp8PiS_j_param_2
)
{
	.reg .pred 	%p<8>;
	.reg .b32 	%r<56>;
	.reg .b64 	%rd<29>;


	ld.param.u64 	%rd5, [_Z17reduceUnrollWarp8PiS_j_param_0];
	ld.param.u64 	%rd4, [_Z17reduceUnrollWarp8PiS_j_param_1];
	ld.param.u32 	%r9, [_Z17reduceUnrollWarp8PiS_j_param_2];
	cvta.to.global.u64 	%rd1, %rd5;
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r55, %ntid.x;
	mul.lo.s32 	%r10, %r1, %r55;
	shl.b32 	%r3, %r10, 3;
	mov.u32 	%r4, %tid.x;
	add.s32 	%r5, %r3, %r4;
	setp.ge.u32 	%p1, %r4, %r9;
	@%p1 bra 	$L__BB4_11;

	mad.lo.s32 	%r6, %r55, 7, %r5;
	setp.ge.u32 	%p2, %r6, %r9;
	@%p2 bra 	$L__BB4_3;

	mul.wide.u32 	%rd6, %r5, 4;
	add.s64 	%rd7, %rd1, %rd6;
	add.s32 	%r11, %r5, %r55;
	mul.wide.u32 	%rd8, %r11, 4;
	add.s64 	%rd9, %rd1, %rd8;
	add.s32 	%r12, %r11, %r55;
	mul.wide.u32 	%rd10, %r12, 4;
	add.s64 	%rd11, %rd1, %rd10;
	add.s32 	%r13, %r12, %r55;
	mul.wide.u32 	%rd12, %r13, 4;
	add.s64 	%rd13, %rd1, %rd12;
	add.s32 	%r14, %r13, %r55;
	mul.wide.u32 	%rd14, %r14, 4;
	add.s64 	%rd15, %rd1, %rd14;
	add.s32 	%r15, %r14, %r55;
	mul.wide.u32 	%rd16, %r15, 4;
	add.s64 	%rd17, %rd1, %rd16;
	add.s32 	%r16, %r15, %r55;
	mul.wide.u32 	%rd18, %r16, 4;
	add.s64 	%rd19, %rd1, %rd18;
	mul.wide.u32 	%rd20, %r6, 4;
	add.s64 	%rd21, %rd1, %rd20;
	ld.global.u32 	%r17, [%rd9];
	ld.global.u32 	%r18, [%rd7];
	add.s32 	%r19, %r17, %r18;
	ld.global.u32 	%r20, [%rd11];
	add.s32 	%r21, %r19, %r20;
	ld.global.u32 	%r22, [%rd13];
	add.s32 	%r23, %r21, %r22;
	ld.global.u32 	%r24, [%rd15];
	add.s32 	%r25, %r23, %r24;
	ld.global.u32 	%r26, [%rd17];
	add.s32 	%r27, %r25, %r26;
	ld.global.u32 	%r28, [%rd19];
	add.s32 	%r29, %r27, %r28;
	ld.global.u32 	%r30, [%rd21];
	add.s32 	%r31, %r29, %r30;
	st.global.u32 	[%rd7], %r31;

$L__BB4_3:
	mul.wide.u32 	%rd22, %r3, 4;
	add.s64 	%rd2, %rd1, %rd22;
	bar.sync 	0;
	mul.wide.u32 	%rd23, %r4, 4;
	add.s64 	%rd3, %rd2, %rd23;
	setp.lt.u32 	%p3, %r55, 66;
	@%p3 bra 	$L__BB4_7;

$L__BB4_4:
	shr.u32 	%r8, %r55, 1;
	setp.ge.u32 	%p4, %r4, %r8;
	@%p4 bra 	$L__BB4_6;

	add.s32 	%r32, %r8, %r4;
	mul.wide.u32 	%rd24, %r32, 4;
	add.s64 	%rd25, %rd2, %rd24;
	ld.global.u32 	%r33, [%rd3];
	ld.global.u32 	%r34, [%rd25];
	add.s32 	%r35, %r33, %r34;
	st.global.u32 	[%rd3], %r35;

$L__BB4_6:
	bar.sync 	0;
	setp.gt.u32 	%p5, %r55, 131;
	mov.u32 	%r55, %r8;
	@%p5 bra 	$L__BB4_4;

$L__BB4_7:
	setp.gt.u32 	%p6, %r4, 31;
	@%p6 bra 	$L__BB4_9;

	ld.volatile.global.u32 	%r36, [%rd3];
	ld.volatile.global.u32 	%r37, [%rd3+128];
	add.s32 	%r38, %r36, %r37;
	st.volatile.global.u32 	[%rd3], %r38;
	ld.volatile.global.u32 	%r39, [%rd3];
	ld.volatile.global.u32 	%r40, [%rd3+64];
	add.s32 	%r41, %r39, %r40;
	st.volatile.global.u32 	[%rd3], %r41;
	ld.volatile.global.u32 	%r42, [%rd3];
	ld.volatile.global.u32 	%r43, [%rd3+32];
	add.s32 	%r44, %r42, %r43;
	st.volatile.global.u32 	[%rd3], %r44;
	ld.volatile.global.u32 	%r45, [%rd3];
	ld.volatile.global.u32 	%r46, [%rd3+16];
	add.s32 	%r47, %r45, %r46;
	st.volatile.global.u32 	[%rd3], %r47;
	ld.volatile.global.u32 	%r48, [%rd3];
	ld.volatile.global.u32 	%r49, [%rd3+8];
	add.s32 	%r50, %r48, %r49;
	st.volatile.global.u32 	[%rd3], %r50;
	ld.volatile.global.u32 	%r51, [%rd3];
	ld.volatile.global.u32 	%r52, [%rd3+4];
	add.s32 	%r53, %r51, %r52;
	st.volatile.global.u32 	[%rd3], %r53;

$L__BB4_9:
	setp.ne.s32 	%p7, %r4, 0;
	@%p7 bra 	$L__BB4_11;

	ld.global.u32 	%r54, [%rd2];
	cvta.to.global.u64 	%rd26, %rd4;
	mul.wide.u32 	%rd27, %r1, 4;
	add.s64 	%rd28, %rd26, %rd27;
	st.global.u32 	[%rd28], %r54;

$L__BB4_11:
	ret;

}
	// .globl	_Z25reduceCompleteUnrollWarp8PiS_j
.visible .entry _Z25reduceCompleteUnrollWarp8PiS_j(
	.param .u64 _Z25reduceCompleteUnrollWarp8PiS_j_param_0,
	.param .u64 _Z25reduceCompleteUnrollWarp8PiS_j_param_1,
	.param .u32 _Z25reduceCompleteUnrollWarp8PiS_j_param_2
)
{
	.reg .pred 	%p<17>;
	.reg .b32 	%r<61>;
	.reg .b64 	%rd<27>;


	ld.param.u64 	%rd5, [_Z25reduceCompleteUnrollWarp8PiS_j_param_0];
	ld.param.u64 	%rd4, [_Z25reduceCompleteUnrollWarp8PiS_j_param_1];
	ld.param.u32 	%r7, [_Z25reduceCompleteUnrollWarp8PiS_j_param_2];
	cvta.to.global.u64 	%rd1, %rd5;
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %ntid.x;
	mul.lo.s32 	%r8, %r1, %r2;
	shl.b32 	%r3, %r8, 3;
	mov.u32 	%r4, %tid.x;
	add.s32 	%r5, %r3, %r4;
	setp.ge.u32 	%p1, %r4, %r7;
	@%p1 bra 	$L__BB5_15;

	mad.lo.s32 	%r6, %r2, 7, %r5;
	setp.ge.u32 	%p2, %r6, %r7;
	@%p2 bra 	$L__BB5_3;

	mul.wide.u32 	%rd6, %r5, 4;
	add.s64 	%rd7, %rd1, %rd6;
	add.s32 	%r9, %r5, %r2;
	mul.wide.u32 	%rd8, %r9, 4;
	add.s64 	%rd9, %rd1, %rd8;
	add.s32 	%r10, %r9, %r2;
	mul.wide.u32 	%rd10, %r10, 4;
	add.s64 	%rd11, %rd1, %rd10;
	add.s32 	%r11, %r10, %r2;
	mul.wide.u32 	%rd12, %r11, 4;
	add.s64 	%rd13, %rd1, %rd12;
	add.s32 	%r12, %r11, %r2;
	mul.wide.u32 	%rd14, %r12, 4;
	add.s64 	%rd15, %rd1, %rd14;
	add.s32 	%r13, %r12, %r2;
	mul.wide.u32 	%rd16, %r13, 4;
	add.s64 	%rd17, %rd1, %rd16;
	add.s32 	%r14, %r13, %r2;
	mul.wide.u32 	%rd18, %r14, 4;
	add.s64 	%rd19, %rd1, %rd18;
	mul.wide.u32 	%rd20, %r6, 4;
	add.s64 	%rd21, %rd1, %rd20;
	ld.global.u32 	%r15, [%rd9];
	ld.global.u32 	%r16, [%rd7];
	add.s32 	%r17, %r15, %r16;
	ld.global.u32 	%r18, [%rd11];
	add.s32 	%r19, %r17, %r18;
	ld.global.u32 	%r20, [%rd13];
	add.s32 	%r21, %r19, %r20;
	ld.global.u32 	%r22, [%rd15];
	add.s32 	%r23, %r21, %r22;
	ld.global.u32 	%r24, [%rd17];
	add.s32 	%r25, %r23, %r24;
	ld.global.u32 	%r26, [%rd19];
	add.s32 	%r27, %r25, %r26;
	ld.global.u32 	%r28, [%rd21];
	add.s32 	%r29, %r27, %r28;
	st.global.u32 	[%rd7], %r29;

$L__BB5_3:
	mul.wide.u32 	%rd22, %r3, 4;
	add.s64 	%rd2, %rd1, %rd22;
	bar.sync 	0;
	setp.gt.u32 	%p3, %r4, 511;
	setp.lt.u32 	%p4, %r2, 1024;
	mul.wide.u32 	%rd23, %r4, 4;
	add.s64 	%rd3, %rd2, %rd23;
	or.pred  	%p5, %p4, %p3;
	@%p5 bra 	$L__BB5_5;

	ld.global.u32 	%r30, [%rd3];
	ld.global.u32 	%r31, [%rd3+2048];
	add.s32 	%r32, %r30, %r31;
	st.global.u32 	[%rd3], %r32;

$L__BB5_5:
	bar.sync 	0;
	setp.gt.u32 	%p6, %r4, 255;
	setp.lt.u32 	%p7, %r2, 512;
	or.pred  	%p8, %p7, %p6;
	@%p8 bra 	$L__BB5_7;

	ld.global.u32 	%r33, [%rd3];
	ld.global.u32 	%r34, [%rd3+1024];
	add.s32 	%r35, %r33, %r34;
	st.global.u32 	[%rd3], %r35;

$L__BB5_7:
	bar.sync 	0;
	setp.gt.u32 	%p9, %r4, 127;
	setp.lt.u32 	%p10, %r2, 256;
	or.pred  	%p11, %p10, %p9;
	@%p11 bra 	$L__BB5_9;

	ld.global.u32 	%r36, [%rd3];
	ld.global.u32 	%r37, [%rd3+512];
	add.s32 	%r38, %r36, %r37;
	st.global.u32 	[%rd3], %r38;

$L__BB5_9:
	bar.sync 	0;
	setp.gt.u32 	%p12, %r4, 63;
	setp.lt.u32 	%p13, %r2, 128;
	or.pred  	%p14, %p13, %p12;
	@%p14 bra 	$L__BB5_11;

	ld.global.u32 	%r39, [%rd3];
	ld.global.u32 	%r40, [%rd3+256];
	add.s32 	%r41, %r39, %r40;
	st.global.u32 	[%rd3], %r41;

$L__BB5_11:
	bar.sync 	0;
	setp.gt.u32 	%p15, %r4, 31;
	@%p15 bra 	$L__BB5_13;

	ld.volatile.global.u32 	%r42, [%rd3];
	ld.volatile.global.u32 	%r43, [%rd3+128];
	add.s32 	%r44, %r42, %r43;
	st.volatile.global.u32 	[%rd3], %r44;
	ld.volatile.global.u32 	%r45, [%rd3];
	ld.volatile.global.u32 	%r46, [%rd3+64];
	add.s32 	%r47, %r45, %r46;
	st.volatile.global.u32 	[%rd3], %r47;
	ld.volatile.global.u32 	%r48, [%rd3];
	ld.volatile.global.u32 	%r49, [%rd3+32];
	add.s32 	%r50, %r48, %r49;
	st.volatile.global.u32 	[%rd3], %r50;
	ld.volatile.global.u32 	%r51, [%rd3];
	ld.volatile.global.u32 	%r52, [%rd3+16];
	add.s32 	%r53, %r51, %r52;
	st.volatile.global.u32 	[%rd3], %r53;
	ld.volatile.global.u32 	%r54, [%rd3];
	ld.volatile.global.u32 	%r55, [%rd3+8];
	add.s32 	%r56, %r54, %r55;
	st.volatile.global.u32 	[%rd3], %r56;
	ld.volatile.global.u32 	%r57, [%rd3];
	ld.volatile.global.u32 	%r58, [%rd3+4];
	add.s32 	%r59, %r57, %r58;
	st.volatile.global.u32 	[%rd3], %r59;

$L__BB5_13:
	setp.ne.s32 	%p16, %r4, 0;
	@%p16 bra 	$L__BB5_15;

	ld.global.u32 	%r60, [%rd2];
	cvta.to.global.u64 	%rd24, %rd4;
	mul.wide.u32 	%rd25, %r1, 4;
	add.s64 	%rd26, %rd24, %rd25;
	st.global.u32 	[%rd26], %r60;

$L__BB5_15:
	ret;

}
	// .globl	_Z20reduceCompleteUnrollILj1024EEvPiS0_j
.visible .entry _Z20reduceCompleteUnrollILj1024EEvPiS0_j(
	.param .u64 _Z20reduceCompleteUnrollILj1024EEvPiS0_j_param_0,
	.param .u64 _Z20reduceCompleteUnrollILj1024EEvPiS0_j_param_1,
	.param .u32 _Z20reduceCompleteUnrollILj1024EEvPiS0_j_param_2
)
{
	.reg .pred 	%p<9>;
	.reg .b32 	%r<61>;
	.reg .b64 	%rd<27>;


	ld.param.u64 	%rd5, [_Z20reduceCompleteUnrollILj1024EEvPiS0_j_param_0];
	ld.param.u64 	%rd4, [_Z20reduceCompleteUnrollILj1024EEvPiS0_j_param_1];
	ld.param.u32 	%r7, [_Z20reduceCompleteUnrollILj1024EEvPiS0_j_param_2];
	cvta.to.global.u64 	%rd1, %rd5;
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %ntid.x;
	mul.lo.s32 	%r8, %r1, %r2;
	shl.b32 	%r3, %r8, 3;
	mov.u32 	%r4, %tid.x;
	add.s32 	%r5, %r3, %r4;
	setp.ge.u32 	%p1, %r4, %r7;
	@%p1 bra 	$L__BB6_15;

	mad.lo.s32 	%r6, %r2, 7, %r5;
	setp.ge.u32 	%p2, %r6, %r7;
	@%p2 bra 	$L__BB6_3;

	mul.wide.u32 	%rd6, %r5, 4;
	add.s64 	%rd7, %rd1, %rd6;
	add.s32 	%r9, %r5, %r2;
	mul.wide.u32 	%rd8, %r9, 4;
	add.s64 	%rd9, %rd1, %rd8;
	add.s32 	%r10, %r9, %r2;
	mul.wide.u32 	%rd10, %r10, 4;
	add.s64 	%rd11, %rd1, %rd10;
	add.s32 	%r11, %r10, %r2;
	mul.wide.u32 	%rd12, %r11, 4;
	add.s64 	%rd13, %rd1, %rd12;
	add.s32 	%r12, %r11, %r2;
	mul.wide.u32 	%rd14, %r12, 4;
	add.s64 	%rd15, %rd1, %rd14;
	add.s32 	%r13, %r12, %r2;
	mul.wide.u32 	%rd16, %r13, 4;
	add.s64 	%rd17, %rd1, %rd16;
	add.s32 	%r14, %r13, %r2;
	mul.wide.u32 	%rd18, %r14, 4;
	add.s64 	%rd19, %rd1, %rd18;
	mul.wide.u32 	%rd20, %r6, 4;
	add.s64 	%rd21, %rd1, %rd20;
	ld.global.u32 	%r15, [%rd9];
	ld.global.u32 	%r16, [%rd7];
	add.s32 	%r17, %r15, %r16;
	ld.global.u32 	%r18, [%rd11];
	add.s32 	%r19, %r17, %r18;
	ld.global.u32 	%r20, [%rd13];
	add.s32 	%r21, %r19, %r20;
	ld.global.u32 	%r22, [%rd15];
	add.s32 	%r23, %r21, %r22;
	ld.global.u32 	%r24, [%rd17];
	add.s32 	%r25, %r23, %r24;
	ld.global.u32 	%r26, [%rd19];
	add.s32 	%r27, %r25, %r26;
	ld.global.u32 	%r28, [%rd21];
	add.s32 	%r29, %r27, %r28;
	st.global.u32 	[%rd7], %r29;

$L__BB6_3:
	mul.wide.u32 	%rd22, %r3, 4;
	add.s64 	%rd2, %rd1, %rd22;
	bar.sync 	0;
	mul.wide.u32 	%rd23, %r4, 4;
	add.s64 	%rd3, %rd2, %rd23;
	setp.gt.u32 	%p3, %r4, 511;
	@%p3 bra 	$L__BB6_5;

	ld.global.u32 	%r30, [%rd3];
	ld.global.u32 	%r31, [%rd3+2048];
	add.s32 	%r32, %r30, %r31;
	st.global.u32 	[%rd3], %r32;

$L__BB6_5:
	bar.sync 	0;
	setp.gt.u32 	%p4, %r4, 255;
	@%p4 bra 	$L__BB6_7;

	ld.global.u32 	%r33, [%rd3];
	ld.global.u32 	%r34, [%rd3+1024];
	add.s32 	%r35, %r33, %r34;
	st.global.u32 	[%rd3], %r35;

$L__BB6_7:
	bar.sync 	0;
	setp.gt.u32 	%p5, %r4, 127;
	@%p5 bra 	$L__BB6_9;

	ld.global.u32 	%r36, [%rd3];
	ld.global.u32 	%r37, [%rd3+512];
	add.s32 	%r38, %r36, %r37;
	st.global.u32 	[%rd3], %r38;

$L__BB6_9:
	bar.sync 	0;
	setp.gt.u32 	%p6, %r4, 63;
	@%p6 bra 	$L__BB6_11;

	ld.global.u32 	%r39, [%rd3];
	ld.global.u32 	%r40, [%rd3+256];
	add.s32 	%r41, %r39, %r40;
	st.global.u32 	[%rd3], %r41;

$L__BB6_11:
	bar.sync 	0;
	setp.gt.u32 	%p7, %r4, 31;
	@%p7 bra 	$L__BB6_13;

	ld.volatile.global.u32 	%r42, [%rd3];
	ld.volatile.global.u32 	%r43, [%rd3+128];
	add.s32 	%r44, %r42, %r43;
	st.volatile.global.u32 	[%rd3], %r44;
	ld.volatile.global.u32 	%r45, [%rd3];
	ld.volatile.global.u32 	%r46, [%rd3+64];
	add.s32 	%r47, %r45, %r46;
	st.volatile.global.u32 	[%rd3], %r47;
	ld.volatile.global.u32 	%r48, [%rd3];
	ld.volatile.global.u32 	%r49, [%rd3+32];
	add.s32 	%r50, %r48, %r49;
	st.volatile.global.u32 	[%rd3], %r50;
	ld.volatile.global.u32 	%r51, [%rd3];
	ld.volatile.global.u32 	%r52, [%rd3+16];
	add.s32 	%r53, %r51, %r52;
	st.volatile.global.u32 	[%rd3], %r53;
	ld.volatile.global.u32 	%r54, [%rd3];
	ld.volatile.global.u32 	%r55, [%rd3+8];
	add.s32 	%r56, %r54, %r55;
	st.volatile.global.u32 	[%rd3], %r56;
	ld.volatile.global.u32 	%r57, [%rd3];
	ld.volatile.global.u32 	%r58, [%rd3+4];
	add.s32 	%r59, %r57, %r58;
	st.volatile.global.u32 	[%rd3], %r59;

$L__BB6_13:
	setp.ne.s32 	%p8, %r4, 0;
	@%p8 bra 	$L__BB6_15;

	ld.global.u32 	%r60, [%rd2];
	cvta.to.global.u64 	%rd24, %rd4;
	mul.wide.u32 	%rd25, %r1, 4;
	add.s64 	%rd26, %rd24, %rd25;
	st.global.u32 	[%rd26], %r60;

$L__BB6_15:
	ret;

}
	// .globl	_Z20reduceCompleteUnrollILj512EEvPiS0_j
.visible .entry _Z20reduceCompleteUnrollILj512EEvPiS0_j(
	.param .u64 _Z20reduceCompleteUnrollILj512EEvPiS0_j_param_0,
	.param .u64 _Z20reduceCompleteUnrollILj512EEvPiS0_j_param_1,
	.param .u32 _Z20reduceCompleteUnrollILj512EEvPiS0_j_param_2
)
{
	.reg .pred 	%p<8>;
	.reg .b32 	%r<58>;
	.reg .b64 	%rd<27>;


	ld.param.u64 	%rd5, [_Z20reduceCompleteUnrollILj512EEvPiS0_j_param_0];
	ld.param.u64 	%rd4, [_Z20reduceCompleteUnrollILj512EEvPiS0_j_param_1];
	ld.param.u32 	%r7, [_Z20reduceCompleteUnrollILj512EEvPiS0_j_param_2];
	cvta.to.global.u64 	%rd1, %rd5;
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %ntid.x;
	mul.lo.s32 	%r8, %r1, %r2;
	shl.b32 	%r3, %r8, 3;
	mov.u32 	%r4, %tid.x;
	add.s32 	%r5, %r3, %r4;
	setp.ge.u32 	%p1, %r4, %r7;
	@%p1 bra 	$L__BB7_13;

	mad.lo.s32 	%r6, %r2, 7, %r5;
	setp.ge.u32 	%p2, %r6, %r7;
	@%p2 bra 	$L__BB7_3;

	mul.wide.u32 	%rd6, %r5, 4;
	add.s64 	%rd7, %rd1, %rd6;
	add.s32 	%r9, %r5, %r2;
	mul.wide.u32 	%rd8, %r9, 4;
	add.s64 	%rd9, %rd1, %rd8;
	add.s32 	%r10, %r9, %r2;
	mul.wide.u32 	%rd10, %r10, 4;
	add.s64 	%rd11, %rd1, %rd10;
	add.s32 	%r11, %r10, %r2;
	mul.wide.u32 	%rd12, %r11, 4;
	add.s64 	%rd13, %rd1, %rd12;
	add.s32 	%r12, %r11, %r2;
	mul.wide.u32 	%rd14, %r12, 4;
	add.s64 	%rd15, %rd1, %rd14;
	add.s32 	%r13, %r12, %r2;
	mul.wide.u32 	%rd16, %r13, 4;
	add.s64 	%rd17, %rd1, %rd16;
	add.s32 	%r14, %r13, %r2;
	mul.wide.u32 	%rd18, %r14, 4;
	add.s64 	%rd19, %rd1, %rd18;
	mul.wide.u32 	%rd20, %r6, 4;
	add.s64 	%rd21, %rd1, %rd20;
	ld.global.u32 	%r15, [%rd9];
	ld.global.u32 	%r16, [%rd7];
	add.s32 	%r17, %r15, %r16;
	ld.global.u32 	%r18, [%rd11];
	add.s32 	%r19, %r17, %r18;
	ld.global.u32 	%r20, [%rd13];
	add.s32 	%r21, %r19, %r20;
	ld.global.u32 	%r22, [%rd15];
	add.s32 	%r23, %r21, %r22;
	ld.global.u32 	%r24, [%rd17];
	add.s32 	%r25, %r23, %r24;
	ld.global.u32 	%r26, [%rd19];
	add.s32 	%r27, %r25, %r26;
	ld.global.u32 	%r28, [%rd21];
	add.s32 	%r29, %r27, %r28;
	st.global.u32 	[%rd7], %r29;

$L__BB7_3:
	mul.wide.u32 	%rd22, %r3, 4;
	add.s64 	%rd2, %rd1, %rd22;
	bar.sync 	0;
	bar.sync 	0;
	mul.wide.u32 	%rd23, %r4, 4;
	add.s64 	%rd3, %rd2, %rd23;
	setp.gt.u32 	%p3, %r4, 255;
	@%p3 bra 	$L__BB7_5;

	ld.global.u32 	%r30, [%rd3];
	ld.global.u32 	%r31, [%rd3+1024];
	add.s32 	%r32, %r30, %r31;
	st.global.u32 	[%rd3], %r32;

$L__BB7_5:
	bar.sync 	0;
	setp.gt.u32 	%p4, %r4, 127;
	@%p4 bra 	$L__BB7_7;

	ld.global.u32 	%r33, [%rd3];
	ld.global.u32 	%r34, [%rd3+512];
	add.s32 	%r35, %r33, %r34;
	st.global.u32 	[%rd3], %r35;

$L__BB7_7:
	bar.sync 	0;
	setp.gt.u32 	%p5, %r4, 63;
	@%p5 bra 	$L__BB7_9;

	ld.global.u32 	%r36, [%rd3];
	ld.global.u32 	%r37, [%rd3+256];
	add.s32 	%r38, %r36, %r37;
	st.global.u32 	[%rd3], %r38;

$L__BB7_9:
	bar.sync 	0;
	setp.gt.u32 	%p6, %r4, 31;
	@%p6 bra 	$L__BB7_11;

	ld.volatile.global.u32 	%r39, [%rd3];
	ld.volatile.global.u32 	%r40, [%rd3+128];
	add.s32 	%r41, %r39, %r40;
	st.volatile.global.u32 	[%rd3], %r41;
	ld.volatile.global.u32 	%r42, [%rd3];
	ld.volatile.global.u32 	%r43, [%rd3+64];
	add.s32 	%r44, %r42, %r43;
	st.volatile.global.u32 	[%rd3], %r44;
	ld.volatile.global.u32 	%r45, [%rd3];
	ld.volatile.global.u32 	%r46, [%rd3+32];
	add.s32 	%r47, %r45, %r46;
	st.volatile.global.u32 	[%rd3], %r47;
	ld.volatile.global.u32 	%r48, [%rd3];
	ld.volatile.global.u32 	%r49, [%rd3+16];
	add.s32 	%r50, %r48, %r49;
	st.volatile.global.u32 	[%rd3], %r50;
	ld.volatile.global.u32 	%r51, [%rd3];
	ld.volatile.global.u32 	%r52, [%rd3+8];
	add.s32 	%r53, %r51, %r52;
	st.volatile.global.u32 	[%rd3], %r53;
	ld.volatile.global.u32 	%r54, [%rd3];
	ld.volatile.global.u32 	%r55, [%rd3+4];
	add.s32 	%r56, %r54, %r55;
	st.volatile.global.u32 	[%rd3], %r56;

$L__BB7_11:
	setp.ne.s32 	%p7, %r4, 0;
	@%p7 bra 	$L__BB7_13;

	ld.global.u32 	%r57, [%rd2];
	cvta.to.global.u64 	%rd24, %rd4;
	mul.wide.u32 	%rd25, %r1, 4;
	add.s64 	%rd26, %rd24, %rd25;
	st.global.u32 	[%rd26], %r57;

$L__BB7_13:
	ret;

}
	// .globl	_Z20reduceCompleteUnrollILj256EEvPiS0_j
.visible .entry _Z20reduceCompleteUnrollILj256EEvPiS0_j(
	.param .u64 _Z20reduceCompleteUnrollILj256EEvPiS0_j_param_0,
	.param .u64 _Z20reduceCompleteUnrollILj256EEvPiS0_j_param_1,
	.param .u32 _Z20reduceCompleteUnrollILj256EEvPiS0_j_param_2
)
{
	.reg .pred 	%p<7>;
	.reg .b32 	%r<55>;
	.reg .b64 	%rd<27>;


	ld.param.u64 	%rd5, [_Z20reduceCompleteUnrollILj256EEvPiS0_j_param_0];
	ld.param.u64 	%rd4, [_Z20reduceCompleteUnrollILj256EEvPiS0_j_param_1];
	ld.param.u32 	%r7, [_Z20reduceCompleteUnrollILj256EEvPiS0_j_param_2];
	cvta.to.global.u64 	%rd1, %rd5;
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %ntid.x;
	mul.lo.s32 	%r8, %r1, %r2;
	shl.b32 	%r3, %r8, 3;
	mov.u32 	%r4, %tid.x;
	add.s32 	%r5, %r3, %r4;
	setp.ge.u32 	%p1, %r4, %r7;
	@%p1 bra 	$L__BB8_11;

	mad.lo.s32 	%r6, %r2, 7, %r5;
	setp.ge.u32 	%p2, %r6, %r7;
	@%p2 bra 	$L__BB8_3;

	mul.wide.u32 	%rd6, %r5, 4;
	add.s64 	%rd7, %rd1, %rd6;
	add.s32 	%r9, %r5, %r2;
	mul.wide.u32 	%rd8, %r9, 4;
	add.s64 	%rd9, %rd1, %rd8;
	add.s32 	%r10, %r9, %r2;
	mul.wide.u32 	%rd10, %r10, 4;
	add.s64 	%rd11, %rd1, %rd10;
	add.s32 	%r11, %r10, %r2;
	mul.wide.u32 	%rd12, %r11, 4;
	add.s64 	%rd13, %rd1, %rd12;
	add.s32 	%r12, %r11, %r2;
	mul.wide.u32 	%rd14, %r12, 4;
	add.s64 	%rd15, %rd1, %rd14;
	add.s32 	%r13, %r12, %r2;
	mul.wide.u32 	%rd16, %r13, 4;
	add.s64 	%rd17, %rd1, %rd16;
	add.s32 	%r14, %r13, %r2;
	mul.wide.u32 	%rd18, %r14, 4;
	add.s64 	%rd19, %rd1, %rd18;
	mul.wide.u32 	%rd20, %r6, 4;
	add.s64 	%rd21, %rd1, %rd20;
	ld.global.u32 	%r15, [%rd9];
	ld.global.u32 	%r16, [%rd7];
	add.s32 	%r17, %r15, %r16;
	ld.global.u32 	%r18, [%rd11];
	add.s32 	%r19, %r17, %r18;
	ld.global.u32 	%r20, [%rd13];
	add.s32 	%r21, %r19, %r20;
	ld.global.u32 	%r22, [%rd15];
	add.s32 	%r23, %r21, %r22;
	ld.global.u32 	%r24, [%rd17];
	add.s32 	%r25, %r23, %r24;
	ld.global.u32 	%r26, [%rd19];
	add.s32 	%r27, %r25, %r26;
	ld.global.u32 	%r28, [%rd21];
	add.s32 	%r29, %r27, %r28;
	st.global.u32 	[%rd7], %r29;

$L__BB8_3:
	mul.wide.u32 	%rd22, %r3, 4;
	add.s64 	%rd2, %rd1, %rd22;
	bar.sync 	0;
	bar.sync 	0;
	bar.sync 	0;
	mul.wide.u32 	%rd23, %r4, 4;
	add.s64 	%rd3, %rd2, %rd23;
	setp.gt.u32 	%p3, %r4, 127;
	@%p3 bra 	$L__BB8_5;

	ld.global.u32 	%r30, [%rd3];
	ld.global.u32 	%r31, [%rd3+512];
	add.s32 	%r32, %r30, %r31;
	st.global.u32 	[%rd3], %r32;

$L__BB8_5:
	bar.sync 	0;
	setp.gt.u32 	%p4, %r4, 63;
	@%p4 bra 	$L__BB8_7;

	ld.global.u32 	%r33, [%rd3];
	ld.global.u32 	%r34, [%rd3+256];
	add.s32 	%r35, %r33, %r34;
	st.global.u32 	[%rd3], %r35;

$L__BB8_7:
	bar.sync 	0;
	setp.gt.u32 	%p5, %r4, 31;
	@%p5 bra 	$L__BB8_9;

	ld.volatile.global.u32 	%r36, [%rd3];
	ld.volatile.global.u32 	%r37, [%rd3+128];
	add.s32 	%r38, %r36, %r37;
	st.volatile.global.u32 	[%rd3], %r38;
	ld.volatile.global.u32 	%r39, [%rd3];
	ld.volatile.global.u32 	%r40, [%rd3+64];
	add.s32 	%r41, %r39, %r40;
	st.volatile.global.u32 	[%rd3], %r41;
	ld.volatile.global.u32 	%r42, [%rd3];
	ld.volatile.global.u32 	%r43, [%rd3+32];
	add.s32 	%r44, %r42, %r43;
	st.volatile.global.u32 	[%rd3], %r44;
	ld.volatile.global.u32 	%r45, [%rd3];
	ld.volatile.global.u32 	%r46, [%rd3+16];
	add.s32 	%r47, %r45, %r46;
	st.volatile.global.u32 	[%rd3], %r47;
	ld.volatile.global.u32 	%r48, [%rd3];
	ld.volatile.global.u32 	%r49, [%rd3+8];
	add.s32 	%r50, %r48, %r49;
	st.volatile.global.u32 	[%rd3], %r50;
	ld.volatile.global.u32 	%r51, [%rd3];
	ld.volatile.global.u32 	%r52, [%rd3+4];
	add.s32 	%r53, %r51, %r52;
	st.volatile.global.u32 	[%rd3], %r53;

$L__BB8_9:
	setp.ne.s32 	%p6, %r4, 0;
	@%p6 bra 	$L__BB8_11;

	ld.global.u32 	%r54, [%rd2];
	cvta.to.global.u64 	%rd24, %rd4;
	mul.wide.u32 	%rd25, %r1, 4;
	add.s64 	%rd26, %rd24, %rd25;
	st.global.u32 	[%rd26], %r54;

$L__BB8_11:
	ret;

}
	// .globl	_Z20reduceCompleteUnrollILj128EEvPiS0_j
.visible .entry _Z20reduceCompleteUnrollILj128EEvPiS0_j(
	.param .u64 _Z20reduceCompleteUnrollILj128EEvPiS0_j_param_0,
	.param .u64 _Z20reduceCompleteUnrollILj128EEvPiS0_j_param_1,
	.param .u32 _Z20reduceCompleteUnrollILj128EEvPiS0_j_param_2
)
{
	.reg .pred 	%p<6>;
	.reg .b32 	%r<52>;
	.reg .b64 	%rd<27>;


	ld.param.u64 	%rd5, [_Z20reduceCompleteUnrollILj128EEvPiS0_j_param_0];
	ld.param.u64 	%rd4, [_Z20reduceCompleteUnrollILj128EEvPiS0_j_param_1];
	ld.param.u32 	%r7, [_Z20reduceCompleteUnrollILj128EEvPiS0_j_param_2];
	cvta.to.global.u64 	%rd1, %rd5;
	mov.u32 	%r1, %ctaid.x;
	mov.u32 	%r2, %ntid.x;
	mul.lo.s32 	%r8, %r1, %r2;
	shl.b32 	%r3, %r8, 3;
	mov.u32 	%r4, %tid.x;
	add.s32 	%r5, %r3, %r4;
	setp.ge.u32 	%p1, %r4, %r7;
	@%p1 bra 	$L__BB9_9;

	mad.lo.s32 	%r6, %r2, 7, %r5;
	setp.ge.u32 	%p2, %r6, %r7;
	@%p2 bra 	$L__BB9_3;

	mul.wide.u32 	%rd6, %r5, 4;
	add.s64 	%rd7, %rd1, %rd6;
	add.s32 	%r9, %r5, %r2;
	mul.wide.u32 	%rd8, %r9, 4;
	add.s64 	%rd9, %rd1, %rd8;
	add.s32 	%r10, %r9, %r2;
	mul.wide.u32 	%rd10, %r10, 4;
	add.s64 	%rd11, %rd1, %rd10;
	add.s32 	%r11, %r10, %r2;
	mul.wide.u32 	%rd12, %r11, 4;
	add.s64 	%rd13, %rd1, %rd12;
	add.s32 	%r12, %r11, %r2;
	mul.wide.u32 	%rd14, %r12, 4;
	add.s64 	%rd15, %rd1, %rd14;
	add.s32 	%r13, %r12, %r2;
	mul.wide.u32 	%rd16, %r13, 4;
	add.s64 	%rd17, %rd1, %rd16;
	add.s32 	%r14, %r13, %r2;
	mul.wide.u32 	%rd18, %r14, 4;
	add.s64 	%rd19, %rd1, %rd18;
	mul.wide.u32 	%rd20, %r6, 4;
	add.s64 	%rd21, %rd1, %rd20;
	ld.global.u32 	%r15, [%rd9];
	ld.global.u32 	%r16, [%rd7];
	add.s32 	%r17, %r15, %r16;
	ld.global.u32 	%r18, [%rd11];
	add.s32 	%r19, %r17, %r18;
	ld.global.u32 	%r20, [%rd13];
	add.s32 	%r21, %r19, %r20;
	ld.global.u32 	%r22, [%rd15];
	add.s32 	%r23, %r21, %r22;
	ld.global.u32 	%r24, [%rd17];
	add.s32 	%r25, %r23, %r24;
	ld.global.u32 	%r26, [%rd19];
	add.s32 	%r27, %r25, %r26;
	ld.global.u32 	%r28, [%rd21];
	add.s32 	%r29, %r27, %r28;
	st.global.u32 	[%rd7], %r29;

$L__BB9_3:
	mul.wide.u32 	%rd22, %r3, 4;
	add.s64 	%rd2, %rd1, %rd22;
	bar.sync 	0;
	bar.sync 	0;
	bar.sync 	0;
	bar.sync 	0;
	mul.wide.u32 	%rd23, %r4, 4;
	add.s64 	%rd3, %rd2, %rd23;
	setp.gt.u32 	%p3, %r4, 63;
	@%p3 bra 	$L__BB9_5;

	ld.global.u32 	%r30, [%rd3];
	ld.global.u32 	%r31, [%rd3+256];
	add.s32 	%r32, %r30, %r31;
	st.global.u32 	[%rd3], %r32;

$L__BB9_5:
	bar.sync 	0;
	setp.gt.u32 	%p4, %r4, 31;
	@%p4 bra 	$L__BB9_7;

	ld.volatile.global.u32 	%r33, [%rd3];
	ld.volatile.global.u32 	%r34, [%rd3+128];
	add.s32 	%r35, %r33, %r34;
	st.volatile.global.u32 	[%rd3], %r35;
	ld.volatile.global.u32 	%r36, [%rd3];
	ld.volatile.global.u32 	%r37, [%rd3+64];
	add.s32 	%r38, %r36, %r37;
	st.volatile.global.u32 	[%rd3], %r38;
	ld.volatile.global.u32 	%r39, [%rd3];
	ld.volatile.global.u32 	%r40, [%rd3+32];
	add.s32 	%r41, %r39, %r40;
	st.volatile.global.u32 	[%rd3], %r41;
	ld.volatile.global.u32 	%r42, [%rd3];
	ld.volatile.global.u32 	%r43, [%rd3+16];
	add.s32 	%r44, %r42, %r43;
	st.volatile.global.u32 	[%rd3], %r44;
	ld.volatile.global.u32 	%r45, [%rd3];
	ld.volatile.global.u32 	%r46, [%rd3+8];
	add.s32 	%r47, %r45, %r46;
	st.volatile.global.u32 	[%rd3], %r47;
	ld.volatile.global.u32 	%r48, [%rd3];
	ld.volatile.global.u32 	%r49, [%rd3+4];
	add.s32 	%r50, %r48, %r49;
	st.volatile.global.u32 	[%rd3], %r50;

$L__BB9_7:
	setp.ne.s32 	%p5, %r4, 0;
	@%p5 bra 	$L__BB9_9;

	ld.global.u32 	%r51, [%rd2];
	cvta.to.global.u64 	%rd24, %rd4;
	mul.wide.u32 	%rd25, %r1, 4;
	add.s64 	%rd26, %rd24, %rd25;
	st.global.u32 	[%rd26], %r51;

$L__BB9_9:
	ret;

}

